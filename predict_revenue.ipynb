{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies Setup"
      ],
      "metadata": {
        "id": "wAvwfuiVqExa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LfjY9FMX0Xhb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key_auth3 = 'fad9ac13c7b36b3e05f6b63be16e74f0'\n",
        "path_prefix = './'\n",
        "img_size = 250"
      ],
      "metadata": {
        "id": "5J8aA-UqJBb6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change directory for importing from google drive"
      ],
      "metadata": {
        "id": "1kH0gsiPqk6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4Uyi1BHx0BGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06de64f1-f7b7-4995-9766-e462ac1a302b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "path_prefix = '/content/drive/My Drive/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data setup"
      ],
      "metadata": {
        "id": "G4FRmUvAx3vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_rename(img_name):\n",
        "    return re.sub(r'\\W+', ' ', img_name).lower().strip().replace(' ', '+') + '.jpg'\n",
        "\n",
        "def resize_poster(img, target_size):\n",
        "    img_resized = resize(img, (img_size, int(img.shape[1] * (target_size / img.shape[0]))), anti_aliasing=True)\n",
        "    pad_size_1 = (img_size - img_resized.shape[1]) // 2\n",
        "    pad_size_2 = img_size - img_resized.shape[1] - pad_size_1\n",
        "    img_padded = np.pad(img_resized, [(0, 0), (pad_size_1, pad_size_2), (0, 0)], mode='constant', constant_values=0)\n",
        "    return img_padded"
      ],
      "metadata": {
        "id": "_ufQklad-0qC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import movie data CSV and extend numpy array for poster images"
      ],
      "metadata": {
        "id": "5UJ9cuISDLbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "md_df = pd.read_csv(path_prefix + 'MovieDataEnhanced.zip')\n",
        "# Prepare feature values (convert strings and arrays to numeric values?)\n",
        "movie_data = np.pad(md_df.to_numpy(), [(0, 0), (0, 1)], mode='constant', constant_values=np.nan)"
      ],
      "metadata": {
        "id": "m0PLMtQnqp2w"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read poster images and add to numpy array"
      ],
      "metadata": {
        "id": "OzL0ouf2Dc-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(movie_data.shape[0]):\n",
        "    img_path = path_prefix + 'posters/' + img_rename(movie_data[i,7])\n",
        "    img = resize_poster(io.imread(img_path), img_size)\n",
        "    movie_data[i, -1] = img"
      ],
      "metadata": {
        "id": "LaVqZE-Nx8yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data shape: {}, Poster shape: {}\".format(movie_data.shape, movie_data[0, -1].shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8i0RXyHDohh",
        "outputId": "10444b6a-78ab-47fc-cf96-166328094df1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (1407, 15), Poster shape: (250, 250, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup DNN Classes"
      ],
      "metadata": {
        "id": "3KmrezcjDn1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define base class\n",
        "\n"
      ],
      "metadata": {
        "id": "Pe42HbuCIOsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "    \n",
        "class DNNBase(nn.Module):\n",
        "    # training step\n",
        "    def training_step(self, batch):\n",
        "        img, targets = batch\n",
        "        out = self(img)\n",
        "        loss = F.cross_entropy(out, targets)\n",
        "        acc = accuracy(out, targets)\n",
        "        return loss, acc\n",
        "    \n",
        "    # validation step\n",
        "    def validation_step(self, batch):\n",
        "        img, targets = batch\n",
        "        out = self(img)\n",
        "        loss = F.cross_entropy(out, targets)\n",
        "        acc = accuracy(out, targets)\n",
        "        return {'val_acc':acc.detach(), 'val_loss':loss.detach()}\n",
        "    \n",
        "    # validation epoch end\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()\n",
        "        return {'val_loss':epoch_loss.item(), 'val_acc':epoch_acc.item()}\n",
        "        \n",
        "    # print result end epoch\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}] : train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}, test_acc: {:.4f}\".format(\n",
        "                epoch, result[\"train_loss\"], result[\"train_acc\"], result[\"val_loss\"], result[\"val_acc\"], result[\"test_acc\"]\n",
        "            ))"
      ],
      "metadata": {
        "id": "NGo7fWezEEeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define DNN class with CNN input"
      ],
      "metadata": {
        "id": "wSl_5U7dKXTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PreTrainedResnet18(DNNBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.network = models.resnet18(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "metadata": {
        "id": "TAX5UoySKGWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}